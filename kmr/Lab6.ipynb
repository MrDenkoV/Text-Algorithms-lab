{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from objsize import get_deep_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimportujmy przydatne biblioteki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw zaimportujmy dane, które będziemy wykorzystywać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(name):\n",
    "    data = \"\"\n",
    "    with open(name, 'r') as file:\n",
    "        data = file.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rij = readfile(\"romeo-i-julia-700.txt\")\n",
    "zad = readfile(\"zad6\")\n",
    "data = readfile(\"1997_714.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat zad6 romeo-i-julia-700.txt 1997_714.txt | grep '~'\n",
    "!cat zad6 romeo-i-julia-700.txt 1997_714.txt | grep '\\$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('~')>ord('z')>ord('Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać znak '~' nie występuje w danych wejściowych i jest najpóźniej leksykograficznie. Również '\\\\$' nie występuje w danych wejściowych i przyda się do połączenia pat\\\\$text, ponieważ '&' nie jest unikalny."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Zaimplementować budowę słownika podstawowych składowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw zaimplementujmy funkcję porządkującą etykietowanie ciągu sekwencji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortNRename(seq):\n",
    "    last = None\n",
    "    ix = 0\n",
    "    posix = [None for i in range(len(seq))]\n",
    "    first = {}\n",
    "    for el in sorted([(e, i) for i,e in enumerate(seq)]):\n",
    "        if last and last[0] != el[0]:\n",
    "            ix += 1\n",
    "            first[ix] = el[1]\n",
    "        posix[el[1]] = ix\n",
    "        if last is None:\n",
    "            first[0] = el[1]\n",
    "        last = el\n",
    "    return (posix, first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 4, 2, 0, 3, 1], {0: 3, 1: 0, 2: 2, 3: 4, 4: 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortNRename([(1,2), (3,1), (2,2), (1,1), (2,3), (1,2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozwiązanie zgodne z oczekiwaniami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz zaimplementujmy algorytm KMR, który zbuduje nam BDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmr(txt):\n",
    "    length = len(txt)\n",
    "    fac = math.floor(math.log2(len(txt)))\n",
    "    maxlen = 2**fac\n",
    "    pad = 2**(fac+1)-1\n",
    "    txt += '~'*pad\n",
    "    posix, first = sortNRename(list(txt))\n",
    "    names = {1: posix}\n",
    "    els = {1: first}\n",
    "    for i  in range(1, fac):\n",
    "        p = 2**(i-1)\n",
    "        new = []\n",
    "        for j in range(len(txt)):\n",
    "            if j+p < len(names[p]):\n",
    "                new += [(names[p][j], names[p][j+p])]\n",
    "        posix, first = sortNRename(new)\n",
    "        names[p*2] = posix\n",
    "        els[p*2] = first\n",
    "    return (names, els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names:\n",
      "1 [1, 2, 2, 1, 2, 2, 1, 2, 1]\n",
      "2 [1, 4, 3, 1, 4, 3, 1, 3, 2]\n",
      "4 [2, 7, 5, 2, 7, 4, 1, 6, 3]\n",
      "\n",
      "positions:\n",
      "1 [1, 2]\n",
      "2 [1, 9, 3, 2]\n",
      "4 [7, 1, 9, 6, 3, 8, 2]\n"
     ]
    }
   ],
   "source": [
    "text = \"abbabbaba\"\n",
    "names, entries = kmr(text)\n",
    "print(\"names:\")\n",
    "for k,v in names.items():\n",
    "    print(k, [e+1 for e in v[:len(text)]])\n",
    "print(\"\\npositions:\")\n",
    "for k,v in entries.items():\n",
    "    print(k, [v[e]+1 for e in range(len(v)-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozwiązanie zgodne z oczekiawniami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Zaimplementować wyszukiwanie wzorca korzystając z DBF. Wyszukiwanie ma działać dla każdej długości wzorca nie większej od długości całego tekstu. Czy konieczne jest budowanie nowego DBF dla pat&text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw zróbmy wersję domyślną z budowaniem nowego DBF dla pat&text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPatTxt(pat, txt, pri=True):\n",
    "    assert len(pat)<len(txt)\n",
    "    names, posix = kmr(pat+'$'+txt)\n",
    "    res=[]\n",
    "    if len(pat) in names:\n",
    "        nm=names[len(pat)]\n",
    "        for i in range(len(pat)+1, len(nm)):\n",
    "            if nm[i]==nm[0]:\n",
    "                res += [i-len(pat)-1]\n",
    "    else:\n",
    "        fac = math.floor(math.log2(len(pat)))\n",
    "        pos = len(pat) - 2**fac\n",
    "        nm = names[2**fac]\n",
    "        for i in range(len(pat)+1, len(nm)-(len(pat)-fac)):\n",
    "            if nm[i]==nm[0] and nm[i+pos]==nm[pos]:\n",
    "                res +=[i-len(pat)-1]\n",
    "        \n",
    "    if pri:\n",
    "        print(f\"Found: {len(res)}\")\n",
    "        print(res)\n",
    "    return res, len(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 1\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "findPatTxt(\"aab\", \"babaaab\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 2\n",
      "[0, 1]\n",
      "Found: 1\n",
      "[13]\n",
      "Found: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "findPatTxt(\"AAAA\",\"AAAAABAAABA\")\n",
    "findPatTxt(\"AAAAB\",\"AAAAAAAAAAAAAAAAAB\")\n",
    "findPatTxt(\"ABABAC\",\"ABABABCABABABCABABABC\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać wyniki zgodne z oczekiawnymi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz zastanówmy się, czy musimy za każdym razem budować DBF.\\\n",
    "Dotychczasowo tworzyliśmy pattern\\\\$text, żeby wliczyć pattern do budowy DBF, co znacząco ułatwia sprawdzanie czy podany pattern występuje w tekście.\\\n",
    "Wykorzystujemy to w ten sposób, że możemy z łatwością sprawdzić, jakie \"nazwy\" otrzymały odpowiednie indeksy patternu i później przeszukując text, możemy szukać tylko tych indeksów na odpowiednio odległych pozycjach.\\\n",
    "Jendak, dzięki wykorzystaniu tablicy positions/elements/entires (druga z krotki kmr), jesteśmy w stanie łatwo odczytać jaki ciąg jak jest \"nazwany\".\\\n",
    "Co więcej, podane etykiety są już posortowane leksykograficznie (po fragmencie który reprezentują), co umożliwia nam binsearchowanie odpowiednich etykiet dla naszego patternu.\\\n",
    "Tym sposobem możemy budować DBF tylko jednokrotnie dla konkretnego tekstu, niezależnie od liczby różnych szukanych wzorców, musimy jednak każdorazowo zidentyfikować odpowiednie etykiety dla nowego patternu, co możemy zrobić wykorzystując binsearch - zawsze max 2 binsearch'e (na prefix i sufix), które w sumie pokrywają cały text i każdy jest długości największej mniejszej potęgi dwójki (niż długość patternu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otrzymujemy w ten sposób złożoności:\\\n",
    "O(nlogn) - pamięciowo - dla n = długość textu - niezależnie od patternu.\\\n",
    "O(nlogn) - czasowo - dla n = długość textu - niezależnie od patternu - tworzenie DBF.\\\n",
    "O(nlogk) - czasowo - dla n = długość patternu i k = liczba unikalnych podsłów textu, długości n (a bardziej największej potęgi 2, będącej mniejszą od n).\\\n",
    "O(n) - czasowo - dla n = długość textu - niezależnie od patternu - znalezienie wszystkich wystąpień patternu w tekście, mając już etykiety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binsearch(left, right, test):\n",
    "    if left>right:\n",
    "        return -1\n",
    "    else:\n",
    "        k = (left+right)//2\n",
    "        res = test(k)\n",
    "        if res==0:\n",
    "            return k\n",
    "        elif res>0:\n",
    "            return binsearch(left, k-1, test)\n",
    "        else:\n",
    "            return binsearch(k+1, right, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(binsearch(1, 100, lambda x: x-100))\n",
    "binsearch(1, 100, lambda x: x-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"as\">\"bs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(pat, txt, wej=None, pri=True):\n",
    "#     fac = math.floor(math.log2(len(txt)))\n",
    "#     maxlen = 2**fac\n",
    "#     pad = 2**(fac+1)-1\n",
    "#     txt += '~'*pad\n",
    "    fac = math.floor(math.log2(len(pat)))\n",
    "    maxlen = 2**fac\n",
    "    dif = len(pat)-maxlen\n",
    "    if wej==None:\n",
    "        names, posix = kmr(txt)\n",
    "    else:\n",
    "        names, posix = wej\n",
    "    posix = posix[maxlen]\n",
    "#     print(posix)\n",
    "    name = names[maxlen]\n",
    "    pref = pat[:maxlen]\n",
    "    suf = pat[-maxlen:]\n",
    "#     print(pat, len(pat), 2**fac)\n",
    "#     print(pref, suf)\n",
    "    def test1(k):\n",
    "        if txt[posix[k]:posix[k]+len(pref)] == pref:\n",
    "            return 0\n",
    "        elif txt[posix[k]:posix[k]+len(pref)]>pref:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    def test2(k):\n",
    "        if txt[posix[k]:posix[k]+len(suf)] == suf:\n",
    "            return 0\n",
    "        elif txt[posix[k]:posix[k]+len(suf)] > suf:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "#     print(len(posix))\n",
    "    pix = binsearch(0, len(posix)-1, test1)\n",
    "    six = binsearch(0, len(posix)-1, test2)\n",
    "#     print(pix, six)\n",
    "    res = []\n",
    "    for i in range(len(txt)-maxlen):\n",
    "        if name[i]==pix and name[i+dif]==six:\n",
    "            res += [i]\n",
    "    if pri:\n",
    "        print(f\"Found: {len(res)}\")\n",
    "        print(res)\n",
    "    return res, len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 1\n",
      "[4]\n",
      "Found: 2\n",
      "[0, 1]\n",
      "Found: 1\n",
      "[13]\n",
      "Found: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "find(\"aab\", \"babaaab\")\n",
    "find(\"AAAA\",\"AAAAABAAABA\")\n",
    "find(\"AAAAB\",\"AAAAAAAAAAAAAAAAAB\")\n",
    "find(\"ABABAC\",\"ABABABCABABABCABABABC\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać funkcja działa zgodnie z oczekiwaniami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sprawdzić rzeczywisty czas budowy DBF dla załączonych plików (3 pliki). Porównać z czasem budowy drzewa sufiksów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy implementację drzewa sufiksów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"A node in the suffix tree. \n",
    "    \n",
    "    suffix_node\n",
    "        the index of a node with a matching suffix, representing a suffix link.\n",
    "        -1 indicates this node has no suffix link.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.suffix_node = -1   \n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Node(suffix link: %d)\"%self.suffix_node\n",
    "\n",
    "class Edge(object):\n",
    "    \"\"\"An edge in the suffix tree.\n",
    "    \n",
    "    first_char_index\n",
    "        index of start of string part represented by this edge\n",
    "        \n",
    "    last_char_index\n",
    "        index of end of string part represented by this edge\n",
    "        \n",
    "    source_node_index\n",
    "        index of source node of edge\n",
    "    \n",
    "    dest_node_index\n",
    "        index of destination node of edge\n",
    "    \"\"\"\n",
    "    def __init__(self, first_char_index, last_char_index, source_node_index, dest_node_index):\n",
    "        self.first_char_index = first_char_index\n",
    "        self.last_char_index = last_char_index\n",
    "        self.source_node_index = source_node_index\n",
    "        self.dest_node_index = dest_node_index\n",
    "        \n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.last_char_index - self.first_char_index\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Edge(%d, %d, %d, %d)'% (self.source_node_index, self.dest_node_index \n",
    "                                        ,self.first_char_index, self.last_char_index )\n",
    "\n",
    "\n",
    "class Suffix(object):\n",
    "    \"\"\"Represents a suffix from first_char_index to last_char_index.\n",
    "    \n",
    "    source_node_index\n",
    "        index of node where this suffix starts\n",
    "    \n",
    "    first_char_index\n",
    "        index of start of suffix in string\n",
    "        \n",
    "    last_char_index\n",
    "        index of end of suffix in string\n",
    "    \"\"\"\n",
    "    def __init__(self, source_node_index, first_char_index, last_char_index):\n",
    "        self.source_node_index = source_node_index\n",
    "        self.first_char_index = first_char_index\n",
    "        self.last_char_index = last_char_index\n",
    "        \n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.last_char_index - self.first_char_index\n",
    "                \n",
    "    def explicit(self):\n",
    "        \"\"\"A suffix is explicit if it ends on a node. first_char_index\n",
    "        is set greater than last_char_index to indicate this.\n",
    "        \"\"\"\n",
    "        return self.first_char_index > self.last_char_index\n",
    "    \n",
    "    def implicit(self):\n",
    "        return self.last_char_index >= self.first_char_index\n",
    "\n",
    "        \n",
    "class SuffixTree(object):\n",
    "    \"\"\"A suffix tree for string matching. Uses Ukkonen's algorithm\n",
    "    for construction.\n",
    "    \"\"\"\n",
    "    def __init__(self, string, case_insensitive=False):\n",
    "        \"\"\"\n",
    "        string\n",
    "            the string for which to construct a suffix tree\n",
    "        \"\"\"\n",
    "        self.string = string\n",
    "        self.case_insensitive = case_insensitive\n",
    "        self.N = len(string) - 1\n",
    "        self.nodes = [Node()]\n",
    "        self.edges = {}\n",
    "        self.active = Suffix(0, 0, -1)\n",
    "        if self.case_insensitive:\n",
    "            self.string = self.string.lower()\n",
    "        for i in range(len(string)):\n",
    "            self._add_prefix(i)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \"\"\" \n",
    "        Lists edges in the suffix tree\n",
    "        \"\"\"\n",
    "        curr_index = self.N\n",
    "        s = \"\\tStart \\tEnd \\tSuf \\tFirst \\tLast \\tString\\n\"\n",
    "        values = list(self.edges.values())\n",
    "        values.sort(key=lambda x: x.source_node_index)\n",
    "        for edge in values:\n",
    "            if edge.source_node_index == -1:\n",
    "                continue\n",
    "            s += \"\\t%s \\t%s \\t%s \\t%s \\t%s \\t\"%(edge.source_node_index\n",
    "                    ,edge.dest_node_index \n",
    "                    ,self.nodes[edge.dest_node_index].suffix_node \n",
    "                    ,edge.first_char_index\n",
    "                    ,edge.last_char_index)\n",
    "                    \n",
    "            \n",
    "            top = min(curr_index, edge.last_char_index)\n",
    "            s += self.string[edge.first_char_index:top+1] + \"\\n\"\n",
    "        return s\n",
    "            \n",
    "    def _add_prefix(self, last_char_index):\n",
    "        \"\"\"The core construction method.\n",
    "        \"\"\"\n",
    "        last_parent_node = -1\n",
    "        while True:\n",
    "            parent_node = self.active.source_node_index\n",
    "            if self.active.explicit():\n",
    "                if (self.active.source_node_index, self.string[last_char_index]) in self.edges:\n",
    "                    # prefix is already in tree\n",
    "                    break\n",
    "            else:\n",
    "                e = self.edges[self.active.source_node_index, self.string[self.active.first_char_index]]\n",
    "                if self.string[e.first_char_index + self.active.length + 1] == self.string[last_char_index]:\n",
    "                    # prefix is already in tree\n",
    "                    break\n",
    "                parent_node = self._split_edge(e, self.active)\n",
    "        \n",
    "\n",
    "            self.nodes.append(Node())\n",
    "            e = Edge(last_char_index, self.N, parent_node, len(self.nodes) - 1)\n",
    "            self._insert_edge(e)\n",
    "            \n",
    "            if last_parent_node > 0:\n",
    "                self.nodes[last_parent_node].suffix_node = parent_node\n",
    "            last_parent_node = parent_node\n",
    "            \n",
    "            if self.active.source_node_index == 0:\n",
    "                self.active.first_char_index += 1\n",
    "            else:\n",
    "                self.active.source_node_index = self.nodes[self.active.source_node_index].suffix_node\n",
    "            self._canonize_suffix(self.active)\n",
    "        if last_parent_node > 0:\n",
    "            self.nodes[last_parent_node].suffix_node = parent_node\n",
    "        self.active.last_char_index += 1\n",
    "        self._canonize_suffix(self.active)\n",
    "        \n",
    "    def _insert_edge(self, edge):\n",
    "        self.edges[(edge.source_node_index, self.string[edge.first_char_index])] = edge\n",
    "        \n",
    "    def _remove_edge(self, edge):\n",
    "        self.edges.pop((edge.source_node_index, self.string[edge.first_char_index]))\n",
    "        \n",
    "    def _split_edge(self, edge, suffix):\n",
    "        self.nodes.append(Node())\n",
    "        e = Edge(edge.first_char_index, edge.first_char_index + suffix.length, suffix.source_node_index, len(self.nodes) - 1)\n",
    "        self._remove_edge(edge)\n",
    "        self._insert_edge(e)\n",
    "        self.nodes[e.dest_node_index].suffix_node = suffix.source_node_index  ### need to add node for each edge\n",
    "        edge.first_char_index += suffix.length + 1\n",
    "        edge.source_node_index = e.dest_node_index\n",
    "        self._insert_edge(edge)\n",
    "        return e.dest_node_index\n",
    "\n",
    "    def _canonize_suffix(self, suffix):\n",
    "        \"\"\"This canonizes the suffix, walking along its suffix string until it \n",
    "        is explicit or there are no more matched nodes.\n",
    "        \"\"\"\n",
    "        if not suffix.explicit():\n",
    "            e = self.edges[suffix.source_node_index, self.string[suffix.first_char_index]]\n",
    "            if e.length <= suffix.length:\n",
    "                suffix.first_char_index += e.length + 1\n",
    "                suffix.source_node_index = e.dest_node_index\n",
    "                self._canonize_suffix(suffix)\n",
    " \n",
    "\n",
    "    # Public methods\n",
    "    def find_substring(self, substring):\n",
    "        \"\"\"Returns the index of substring in string or -1 if it\n",
    "        is not found.\n",
    "        \"\"\"\n",
    "        if not substring:\n",
    "            return -1\n",
    "        if self.case_insensitive:\n",
    "            substring = substring.lower()\n",
    "        curr_node = 0\n",
    "        i = 0\n",
    "        while i < len(substring):\n",
    "            edge = self.edges.get((curr_node, substring[i]))\n",
    "            if not edge:\n",
    "                return -1\n",
    "            ln = min(edge.length + 1, len(substring) - i)\n",
    "            if substring[i:i + ln] != self.string[edge.first_char_index:edge.first_char_index + ln]:\n",
    "                return -1\n",
    "            i += edge.length + 1\n",
    "            curr_node = edge.dest_node_index\n",
    "        return edge.first_char_index - len(substring) + ln\n",
    "        \n",
    "    def has_substring(self, substring):\n",
    "        return self.find_substring(substring) != -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budowa drzewa - SuffixTree(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix - zad6\n",
      "9.69 ms ± 2.96 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KMR - zad6\n",
      "22.2 ms ± 1.58 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "Suffix - Romeo i Julia\n",
      "140 ms ± 12.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "KMR - Romeo i Julia\n",
      "690 ms ± 115 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Suffix - ustawa\n",
      "2.91 s ± 183 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "KMR - ustawa\n",
      "22.2 s ± 920 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Suffix - zad6\")\n",
    "%timeit index = SuffixTree(zad)\n",
    "print(\"KMR - zad6\")\n",
    "%timeit index = kmr(zad)\n",
    "print(\"Suffix - Romeo i Julia\")\n",
    "%timeit index = SuffixTree(rij)\n",
    "print(\"KMR - Romeo i Julia\")\n",
    "%timeit index = kmr(rij)\n",
    "print(\"Suffix - ustawa\")\n",
    "%timeit index = SuffixTree(data)\n",
    "print(\"KMR - ustawa\")\n",
    "%timeit index = kmr(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, drzewo suffiksów buduje się szybciej niż KMR - wynika to z różnicy w złożoności obu algorytmów. Drzewo sufiksów można budować w O(n), natomiast DBF wymaga złożoności O(nlogn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Zbadać rzeczywisty rozmiar DBF, porównać z wielkością pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSize(name, txt):\n",
    "    res = kmr(txt)\n",
    "    print(f\"File {name}: Original size - {get_deep_size(txt)}, DBF size - {get_deep_size(res)},\",\n",
    "          f\"Ratio dbf/ori - {get_deep_size(res)/get_deep_size(txt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Zad6: Original size - 1884, DBF size - 682112, Ratio dbf/ori - 362.0552016985138\n",
      "File Romeo i Julia: Original size - 25374, DBF size - 16667580, Ratio dbf/ori - 656.8763301016788\n",
      "File Ustawa: Original size - 493018, DBF size - 381244684, Ratio dbf/ori - 773.2875554239399\n"
     ]
    }
   ],
   "source": [
    "testSize(\"Zad6\", zad)\n",
    "testSize(\"Romeo i Julia\", rij)\n",
    "testSize(\"Ustawa\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać DBF kosztuje bardzo dużo pamięci. Jednak musimy pamiętać że wykorzystujemy O(nlogn) pamięci, co może nie jest aż tak widoczne, przez sporą stałą."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Porównać czas wyszukiwania wzorca przy użyciu DBF z wyszukiwaniem za pomocą KMP dla różnych długości wzorca (np. jedna litera, jedno słowo, jedno zdanie)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy implementację KMP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program for KMP Algorithm \n",
    "def KMPSearch(pat, txt, ver=False): \n",
    "    M = len(pat) \n",
    "    N = len(txt) \n",
    "    \n",
    "    # create lps[] that will hold the longest prefix suffix  \n",
    "    # values for pattern \n",
    "    lps = [0]*M \n",
    "    j = 0 # index for pat[] \n",
    "  \n",
    "    # Preprocess the pattern (calculate lps[] array) \n",
    "    computeLPSArray(pat, M, lps) \n",
    "  \n",
    "    i = 0 # index for txt[] \n",
    "    while i < N: \n",
    "        if pat[j] == txt[i]: \n",
    "            i += 1\n",
    "            j += 1\n",
    "  \n",
    "        if j == M: \n",
    "            if ver:\n",
    "                print(\"Found pattern at index \" + str(i-j))\n",
    "            j = lps[j-1] \n",
    "  \n",
    "        # mismatch after j matches \n",
    "        elif i < N and pat[j] != txt[i]: \n",
    "            # Do not match lps[0..lps[j-1]] characters, \n",
    "            # they will match anyway \n",
    "            if j != 0: \n",
    "                j = lps[j-1] \n",
    "            else: \n",
    "                i += 1\n",
    "\n",
    "\n",
    "def computeLPSArray(pat, M, lps): \n",
    "    len = 0 # length of the previous longest prefix suffix \n",
    "  \n",
    "    lps[0] # lps[0] is always 0 \n",
    "    i = 1\n",
    "  \n",
    "    # the loop calculates lps[i] for i = 1 to M-1 \n",
    "    while i < M: \n",
    "        if pat[i]== pat[len]: \n",
    "            len += 1\n",
    "            lps[i] = len\n",
    "            i += 1\n",
    "        else: \n",
    "            # This is tricky. Consider the example. \n",
    "            # AAACAAAA and i = 7. The idea is similar  \n",
    "            # to search step. \n",
    "            if len != 0: \n",
    "                len = lps[len-1] \n",
    "  \n",
    "                # Also, note that we do not increment i here \n",
    "            else: \n",
    "                lps[i] = 0\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyszukanie KMPSearch(pat, txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zad6\n",
      "KMP - Letter - a\n",
      "309 µs ± 34.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "KMR - Letter - a\n",
      "25.1 ms ± 11.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "KMP - Word - wzorca\n",
      "285 µs ± 20.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "KMR - Word - wzorca\n",
      "19.2 ms ± 620 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "\n",
      "KMP - Sentence - Zaimplementować budowę słownika podstawowych składowych.\n",
      "261 µs ± 6.63 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "KMR - Sentence - Zaimplementować budowę słownika podstawowych składowych.\n",
      "22.3 ms ± 1.64 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "\n",
      "Romeo i Julia\n",
      "KMP - Letter - a\n",
      "3.77 ms ± 174 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KMR - Letter - a\n",
      "750 ms ± 162 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "KMP - Word - piękna\n",
      "3.54 ms ± 41.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KMR - Word - piękna\n",
      "586 ms ± 5.43 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "KMP - Sentence - Całą potomność piękności pozbawia.\n",
      "3.6 ms ± 135 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KMR - Sentence - Całą potomność piękności pozbawia.\n",
      "592 ms ± 6.13 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "\n",
      "Ustawa\n",
      "KMP - Letter - a\n",
      "66.9 ms ± 1.24 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "KMR - Letter - a\n",
      "19.6 s ± 384 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "KMP - Word - Wyrób\n",
      "67.9 ms ± 499 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "KMR - Word - Wyrób\n",
      "19.8 s ± 368 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "KMP - Sentence - Naprawa i odświeżanie obuwia.\n",
      "256 µs ± 7.32 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "KMR - Sentence - Naprawa i odświeżanie obuwia.\n",
      "20 ms ± 1.19 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"zad6\")\n",
    "print(\"KMP - Letter - a\")\n",
    "%timeit index = KMPSearch('a', zad)\n",
    "print(\"KMR - Letter - a\")\n",
    "%timeit index = findPatTxt('a', zad, False)\n",
    "\n",
    "print(\"\\nKMP - Word - wzorca\")\n",
    "%timeit index = KMPSearch('wzorca', zad)\n",
    "print(\"KMR - Word - wzorca\")\n",
    "%timeit index = findPatTxt('wzorca', zad, False)\n",
    "\n",
    "print(\"\\nKMP - Sentence - Zaimplementować budowę słownika podstawowych składowych.\")\n",
    "%timeit index = KMPSearch('Zaimplementować budowę słownika podstawowych składowych.', zad)\n",
    "print(\"KMR - Sentence - Zaimplementować budowę słownika podstawowych składowych.\")\n",
    "%timeit index = findPatTxt('Zaimplementować budowę słownika podstawowych składowych.', zad, False)\n",
    "\n",
    "print(\"\\n\\nRomeo i Julia\")\n",
    "print(\"KMP - Letter - a\")\n",
    "%timeit index = KMPSearch('a', rij)\n",
    "print(\"KMR - Letter - a\")\n",
    "%timeit index = findPatTxt('a', rij, False)\n",
    "\n",
    "print(\"\\nKMP - Word - piękna\")\n",
    "%timeit index = KMPSearch('piękna', rij)\n",
    "print(\"KMR - Word - piękna\")\n",
    "%timeit index = findPatTxt('piękna', rij, False)\n",
    "\n",
    "print(\"\\nKMP - Sentence - Całą potomność piękności pozbawia.\")\n",
    "%timeit index = KMPSearch('Całą potomność piękności pozbawia.', rij)\n",
    "print(\"KMR - Sentence - Całą potomność piękności pozbawia.\")\n",
    "%timeit index = findPatTxt('Całą potomność piękności pozbawia.', rij, False)\n",
    "\n",
    "print(\"\\n\\nUstawa\")\n",
    "print(\"KMP - Letter - a\")\n",
    "%timeit index = KMPSearch('a', data)\n",
    "print(\"KMR - Letter - a\")\n",
    "%timeit index = findPatTxt('a', data, False)\n",
    "\n",
    "print(\"\\nKMP - Word - Wyrób\")\n",
    "%timeit index = KMPSearch('Wyrób', data)\n",
    "print(\"KMR - Word - Wyrób\")\n",
    "%timeit index = findPatTxt('Wyrób', data, False)\n",
    "\n",
    "print(\"\\nKMP - Sentence - Naprawa i odświeżanie obuwia.\")\n",
    "%timeit index = KMPSearch('Naprawa i odświeżanie obuwia.', zad)\n",
    "print(\"KMR - Sentence - Naprawa i odświeżanie obuwia.\")\n",
    "%timeit index = findPatTxt('Naprawa i odświeżanie obuwia.', zad, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać KMP jest dużo szybsze od KMR, co wynika z różnicy złożoności. KMP ma O(n), natomiast KMR ma O(nlogn).\\\n",
    "Pamiętajmy, że w tej wersji budujemy DBF i LPS za każdym razem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zad6\n",
      "KMP - Letter - a\n",
      "326 µs ± 105 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "KMR - Letter - a\n",
      "81.5 µs ± 11.4 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "KMP - Word - wzorca\n",
      "253 µs ± 5.88 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "KMR - Word - wzorca\n",
      "79.7 µs ± 1.6 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "KMP - Sentence - Zaimplementować budowę słownika podstawowych składowych.\n",
      "308 µs ± 125 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "KMR - Sentence - Zaimplementować budowę słownika podstawowych składowych.\n",
      "82.4 µs ± 3.29 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "\n",
      "\n",
      "Romeo i Julia\n",
      "KMP - Letter - a\n",
      "3.53 ms ± 142 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KMR - Letter - a\n",
      "964 µs ± 29.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "KMP - Word - piękna\n",
      "3.55 ms ± 103 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KMR - Word - piękna\n",
      "958 µs ± 106 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "KMP - Sentence - Całą potomność piękności pozbawia.\n",
      "3.55 ms ± 77.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "KMR - Sentence - Całą potomność piękności pozbawia.\n",
      "1.02 ms ± 105 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "\n",
      "Ustawa\n",
      "KMP - Letter - a\n",
      "66.8 ms ± 195 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "KMR - Letter - a\n",
      "18.1 ms ± 142 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "KMP - Word - Wyrób\n",
      "70.3 ms ± 991 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "KMR - Word - Wyrób\n",
      "17.1 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "KMP - Sentence - Naprawa i odświeżanie obuwia.\n",
      "261 µs ± 15.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "KMR - Sentence - Naprawa i odświeżanie obuwia.\n",
      "90.3 µs ± 146 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"zad6\")\n",
    "dbf = kmr(zad)\n",
    "print(\"KMP - Letter - a\")\n",
    "%timeit index = KMPSearch('a', zad)\n",
    "print(\"KMR - Letter - a\")\n",
    "%timeit index = find('a', zad, dbf, False)\n",
    "\n",
    "print(\"\\nKMP - Word - wzorca\")\n",
    "%timeit index = KMPSearch('wzorca', zad)\n",
    "print(\"KMR - Word - wzorca\")\n",
    "%timeit index = find('wzorca', zad, dbf, False)\n",
    "\n",
    "print(\"\\nKMP - Sentence - Zaimplementować budowę słownika podstawowych składowych.\")\n",
    "%timeit index = KMPSearch('Zaimplementować budowę słownika podstawowych składowych.', zad)\n",
    "print(\"KMR - Sentence - Zaimplementować budowę słownika podstawowych składowych.\")\n",
    "%timeit index = find('Zaimplementować budowę słownika podstawowych składowych.', zad, dbf, False)\n",
    "\n",
    "print(\"\\n\\nRomeo i Julia\")\n",
    "dbf = kmr(rij)\n",
    "print(\"KMP - Letter - a\")\n",
    "%timeit index = KMPSearch('a', rij)\n",
    "print(\"KMR - Letter - a\")\n",
    "%timeit index = find('a', rij, dbf, False)\n",
    "\n",
    "print(\"\\nKMP - Word - piękna\")\n",
    "%timeit index = KMPSearch('piękna', rij)\n",
    "print(\"KMR - Word - piękna\")\n",
    "%timeit index = find('piękna', rij, dbf, False)\n",
    "\n",
    "print(\"\\nKMP - Sentence - Całą potomność piękności pozbawia.\")\n",
    "%timeit index = KMPSearch('Całą potomność piękności pozbawia.', rij)\n",
    "print(\"KMR - Sentence - Całą potomność piękności pozbawia.\")\n",
    "%timeit index = find('Całą potomność piękności pozbawia.', rij, dbf, False)\n",
    "\n",
    "print(\"\\n\\nUstawa\")\n",
    "dbf = kmr(data)\n",
    "print(\"KMP - Letter - a\")\n",
    "%timeit index = KMPSearch('a', data)\n",
    "print(\"KMR - Letter - a\")\n",
    "%timeit index = find('a', data, dbf, False)\n",
    "\n",
    "print(\"\\nKMP - Word - Wyrób\")\n",
    "%timeit index = KMPSearch('Wyrób', data)\n",
    "print(\"KMR - Word - Wyrób\")\n",
    "%timeit index = find('Wyrób', data, dbf, False)\n",
    "\n",
    "print(\"\\nKMP - Sentence - Naprawa i odświeżanie obuwia.\")\n",
    "%timeit index = KMPSearch('Naprawa i odświeżanie obuwia.', zad)\n",
    "print(\"KMR - Sentence - Naprawa i odświeżanie obuwia.\")\n",
    "%timeit index = find('Naprawa i odświeżanie obuwia.', zad, dbf, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tym razem policzyliśmy DBF najpierw, a później na tej podstawie wyszukiwaliśmy wzorca w tekście. Jak widać, tym razem KMR wyszukuje wzorce w tekście dużo szybciej niż KMP - oszczędzamy czas na preprocessingu LSP (LSP liczymy na wzorcu, więc nie możemy wykonać takiego preprocessingu na tekście) i tylko jednym liniowym przejściem znajdujemy wszystkie wystąpienia wzorca w teście."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
